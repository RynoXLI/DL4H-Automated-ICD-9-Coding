{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SVM Model\n",
    "\n",
    "In this notebook, we will create the SVM models for the ICD9 multi-label problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('prepared-data.pq')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the X, Y dataset\n",
    "\n",
    "2. Convert codes to binary array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['toks'].values\n",
    "y_raw = data['ICD9_CODE'].astype(str)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(data['ICD9_CODE'].to_list())\n",
    "mlb.classes_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the number of codes, this should match from the pre-processing script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb.classes_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the test/train split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bag-of-words representation and preform TF-IDF.\n",
    "\n",
    "Transform both the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False, min_df=0.001)\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model, for this model we will use SGDClassifier.\n",
    "\n",
    "This classifier preforms the hinge loss which is what SVM uses, and additionally it uses SGD. We use SGD to speed up the model training process.\n",
    "\n",
    "We also use One-vs-Rest strategy with the SVM model, where we create a new binary SVM for each class versus all other labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge', n_jobs=6, class_weight={0: 1, 1: 10}), n_jobs=6)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next use cross-validation to find class probabilties across 5 different folds. We will use the probabilities later to find the best threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "calibrated_clf = MultiOutputClassifier(CalibratedClassifierCV(clf, cv=cv, n_jobs=6), n_jobs=6)\n",
    "calibrated_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = calibrated_clf.predict_proba(X_test)\n",
    "y_pred = np.dstack(y_pred)\n",
    "y_pred = np.transpose(y_pred, (0, 2, 1))\n",
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = (y_pred[:, :, 1] > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1, 0.1)\n",
    "data = []\n",
    "for threshold in thresholds:\n",
    "    y_pred_cls = (y_pred[:, :, 1] > threshold) * 1\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred_cls, average='micro')\n",
    "    data.append((threshold, precision, recall, fscore, support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['threshold', 'precision', 'recall', 'fscore', 'support'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[df['fscore'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"SVM F-score Curve\")\n",
    "plt.plot(df['threshold'], df['fscore'], label='F-Score')\n",
    "plt.plot(df['threshold'], df['recall'], label='Recall')\n",
    "plt.plot(df['threshold'], df['precision'], label='Precision')\n",
    "plt.xlabel('Threshold Cutoff')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.text()\n",
    "plt.savefig('svm-fscore.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('svm-scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "total_time = end - start\n",
    "total_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d716bf7a04a4236457ac4904b85c3b09395e2ba295a5d1cc0de156cec0f44305"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
