{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabeler\n",
    "\n",
    "In this notebook we will train the DeepLabeler architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn as nn\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from functools import partial\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data and pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('prepared-data.pq')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['toks'].apply(lambda x: len(x)).min()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in these vectors as tensors before the collate function saved a lot of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = {word: torch.tensor(vec, device=device, dtype=torch.float) for word, vec in zip(w2v.wv.index_to_key, w2v.wv.vectors)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.y = torch.tensor(np.vstack(self.mlb.fit_transform(data['ICD9_CODE'].to_list())), dtype=torch.float, device=device)\n",
    "        self.W = data['toks'].to_list()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.W[index], self.y[index]\n",
    "    \n",
    "dataset = CustomDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert next(iter(dataset))[-1].shape[0] == dataset.mlb.classes_.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(w2v, max_token_length, data):\n",
    "    \"\"\"\n",
    "    Get word vectors and document vectors for each batch\n",
    "\n",
    "    Arguments:\n",
    "        data: batch data from generator\n",
    "        w2v: Pre-trained Word2Vec model\n",
    "        max_token_length: Maximum length of sequences of tokens to use\n",
    "\n",
    "    Returns:\n",
    "        word_matrix (batch, max_token_length, w2v embedding size), document_vector (batch_size, d2v embedding size), y (batch_size, max_icd9_length)\n",
    "    \"\"\"\n",
    "    W, y = zip(*data)\n",
    "    y = torch.vstack(y)\n",
    "\n",
    "    word_matrix = torch.zeros((len(W), max_token_length, w2v.vector_size), device=device)\n",
    "    # D = torch.vstack(D)\n",
    "    for i, sentence in enumerate(W):\n",
    "        l = []\n",
    "        j = 0\n",
    "        for word in sentence:\n",
    "            if j < 700:\n",
    "                if vecs.get(word) is not None:\n",
    "                    l.append(vecs[word])\n",
    "                    j += 1\n",
    "            else:\n",
    "                break\n",
    "        word_matrix[i, :len(l)] = torch.vstack(l)\n",
    "\n",
    "    return word_matrix, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this cell to test my preprocessing script\n",
    "# I found that minimizing copying tensors over (even in gpu) saves time\n",
    "\n",
    "# # %%timeit\n",
    "# W, D, y = dataset[:10]\n",
    "\n",
    "# word_matrix = torch.zeros((len(W), max_token_length, w2v.vector_size), device=device)\n",
    "# # D = torch.vstack(D)\n",
    "# for i, sentence in enumerate(W):\n",
    "#     j = 0\n",
    "#     l = []\n",
    "#     for word in sentence:\n",
    "#         if j < 700:\n",
    "#             if vecs.get(word) is not None:\n",
    "#                 # word_matrix[i, j] = vecs[word]\n",
    "#                 l.append(vecs[word])\n",
    "#                 j += 1\n",
    "#         else:\n",
    "#             break\n",
    "#     word_matrix[i, :len(l)] = torch.vstack(l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train/test split and create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(dataset)*0.8)\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "max_token_length = 700\n",
    "embedding_size = 100\n",
    "output_size = len(dataset.mlb.classes_)\n",
    "\n",
    "collate_fn = partial(collate, w2v, max_token_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this cell for testing the time to loop, it eventually took 30s to loop through the whole dataset\n",
    "# for W, D, y in tqdm(train_loader):\n",
    "#     pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcuate the convolution kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_volume(W, F, S, P):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Given the input volume size $W$, the kernel/filter size $F$, \n",
    "    the stride $S$, and the amount of zero padding $P$ used on the border, \n",
    "    calculate the output volume size.\n",
    "    Note the output should a integer. \n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here\n",
    "#     raise NotImplementedError\n",
    "    return (W - F + 2*P ) // S + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabeler(nn.Module):\n",
    "    def __init__(self, embedding_size, max_token_length, output_size):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_token_length = max_token_length\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3))\n",
    "        self.cnn2 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(4,4))\n",
    "        self.cnn3 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(5,5))\n",
    "        self.pool1 = nn.MaxPool2d((conv_output_volume(self.max_token_length, 3, 1, 0), conv_output_volume(self.embedding_size, 3, 1, 0)))\n",
    "        self.pool2 = nn.MaxPool2d((conv_output_volume(self.max_token_length, 4, 1, 0), conv_output_volume(self.embedding_size, 4, 1, 0)))\n",
    "        self.pool3 = nn.MaxPool2d((conv_output_volume(self.max_token_length, 5, 1, 0), conv_output_volume(self.embedding_size, 5, 1, 0)))\n",
    "        self.dropout = nn.Dropout(p=0.75)\n",
    "        self.fc1 = nn.Linear(64*3, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, W: torch.Tensor):\n",
    "        W = W.unsqueeze(dim=1)\n",
    "        out1 = self.pool1(self.dropout(torch.relu(self.cnn1(W))))\n",
    "        out2 = self.pool2(self.dropout(torch.relu(self.cnn2(W))))\n",
    "        out3 = self.pool3(self.dropout(torch.relu(self.cnn3(W))))\n",
    "\n",
    "        W_embeddings = torch.concat((out1.squeeze().squeeze(), out2.squeeze().squeeze(), out3.squeeze().squeeze()), dim=1)\n",
    "        \n",
    "        return torch.sigmoid(self.fc1(W_embeddings))\n",
    "\n",
    "model = DeepLabeler(embedding_size, max_token_length, output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion.cuda()\n",
    "model.cuda()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 5\n",
    "epoch_loss = []\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    curr_epoch_loss = []\n",
    "    for W, y in tqdm(train_loader):\n",
    "        \"\"\"\n",
    "        TODO: Within the loop, do the normal training procedures:\n",
    "                pass the input through the model\n",
    "                pass the output through loss_func to compute the loss (name the variable as *loss*)\n",
    "                zero out currently accumulated gradient, use loss.basckward to backprop the gradients, then call optimizer.step\n",
    "        \"\"\"\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # with torch.cuda.amp.autocast():\n",
    "                # forward pass\n",
    "        y_hat = model(W)\n",
    "\n",
    "        # calucate loss\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "    epoch_loss.append(np.mean(curr_epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Epoch Loss\")\n",
    "plt.plot(epoch_loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.text()\n",
    "# plt.savefig('deeplabeler-fscore.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model-no-d2v.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "total_time = end - start_time\n",
    "total_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DeepLabeler(embedding_size, max_token_length, output_size)\n",
    "model2.cuda()\n",
    "model2.load_state_dict(torch.load('model-no-d2v.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = None\n",
    "Y_hat = None\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat_list = []\n",
    "    y_list = []\n",
    "    for W, y in tqdm(val_loader):\n",
    "        y_hat = model2(W).detach().cpu().numpy()\n",
    "        y_list.append(y.detach().cpu().numpy())\n",
    "        y_hat_list.append(y_hat)\n",
    "    Y = np.vstack(y_list)\n",
    "    Y_hat = np.vstack(y_hat_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate at different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1, 0.1)\n",
    "data = []\n",
    "for threshold in tqdm(thresholds):\n",
    "    y_pred_cls = (Y_hat > threshold) * 1\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(Y, y_pred_cls, average='micro')\n",
    "    data.append((threshold, precision, recall, fscore, support))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Results and Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['threshold', 'precision', 'recall', 'fscore', 'support'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[df['fscore'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"DeepLabeler Minus Doc2Vec F-score Curve\")\n",
    "plt.plot(df['threshold'], df['fscore'], label='F-Score')\n",
    "plt.plot(df['threshold'], df['recall'], label='Recall')\n",
    "plt.plot(df['threshold'], df['precision'], label='Precision')\n",
    "plt.xlabel('Threshold Cutoff')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.text()\n",
    "plt.savefig('deeplabeler-fscore-no-d2v.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('deeplabeler-scores-no-d2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this cell for debugging\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION', )\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "total_time = end - start_time\n",
    "total_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
